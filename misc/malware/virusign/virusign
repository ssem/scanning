#!/usr/bin/env python
import os
import argparse
import requests

def run(output):
    for x in xrange(1, 70):
        scrape_page(4, x, output)
    for x in xrange(1, 220):
        scrape_page(3, x, output)
    for x in xrange(1, 170):
        scrape_page(2, x, output)
    for x in xrange(1, 180):
        scrape_page(1, x, output)

def scrape_page(detections, page_number, output):
    http = requests.get(
        url='http://virusign.com/home.php?d=%s&r=100&c=hashes&o=date&s=DESC&p=%s' % (detections, page_number),
        headers={'user-agent':"if you ever get cold just stand in a corner, they are usualy around 90 degrees"})
    for line in http.content.split('\n'):
        if "Download" in line:
            url = line.split('href="')[-1].split('">')[0]
            print 'http://virusign.com%s' % url
            http = requests.get('http://virusign.com%s') % url
            f = open(os.path.join(output, os.path.basename(url)), 'w+')
            f.write(http.content)
            f.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("path", help="path to dir output")
    args = parser.parse_args()
    run(args.path)
